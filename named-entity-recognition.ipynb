{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "5853838bdcd07aeccb2efa859bbf678ba16d810a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "c091edb0cda580d66247062f72c4220a19ec79d3"
   },
   "outputs": [],
   "source": [
    "def coocurrence(*inputs):\n",
    "    com = defaultdict(int)\n",
    "    \n",
    "    for named_entities in inputs:\n",
    "        # Build co-occurrence matrix\n",
    "        for w1, w2 in combinations(sorted(named_entities), 2):\n",
    "            com[w1, w2] += 1\n",
    "            com[w2, w1] += 1  #Including both directions\n",
    "\n",
    "    result = defaultdict(dict)\n",
    "    for (w1, w2), count in com.items():\n",
    "        if w1 != w2:\n",
    "            result[w1][w2] = {'weight': count}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "517cb117c211633b4a8fd840272c9f4517c161f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'a': {'b': {'weight': 2}, 'c': {'weight': 3}, 'd': {'weight': 7}},\n",
       "             'b': {'a': {'weight': 2}, 'c': {'weight': 2}, 'd': {'weight': 5}},\n",
       "             'c': {'a': {'weight': 3}, 'b': {'weight': 2}, 'd': {'weight': 6}},\n",
       "             'd': {'a': {'weight': 7},\n",
       "              'b': {'weight': 5},\n",
       "              'c': {'weight': 6}}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example coocurrence.\n",
    "# Originally d is not a key here (since included in previous coocurrences)\n",
    "# Altered to include ALL now, seems to make difference for my methodology below\n",
    "\n",
    "coocurrence('abcddc', 'bddad', 'cdda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "0595d3b04a0263be87dffee8f4d24b5a911f1395"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snopes_page</th>\n",
       "      <th>topic</th>\n",
       "      <th>claim</th>\n",
       "      <th>claim_label</th>\n",
       "      <th>date_published</th>\n",
       "      <th>date_updated</th>\n",
       "      <th>page_url</th>\n",
       "      <th>page_is_example</th>\n",
       "      <th>page_is_image_credit</th>\n",
       "      <th>page_is_archived</th>\n",
       "      <th>page_is_first_citation</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.snopes.com/georgia-bans-muslim-cult...</td>\n",
       "      <td>politics</td>\n",
       "      <td>Georgia recently became the first U.S. state t...</td>\n",
       "      <td>false</td>\n",
       "      <td>Nov 17th, 2016</td>\n",
       "      <td>Mar 20th, 2017</td>\n",
       "      <td>http://www.legis.ga.gov/Legislation/en-US/disp...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.snopes.com/georgia-bans-muslim-cult...</td>\n",
       "      <td>politics</td>\n",
       "      <td>Georgia recently became the first U.S. state t...</td>\n",
       "      <td>false</td>\n",
       "      <td>Nov 17th, 2016</td>\n",
       "      <td>Mar 20th, 2017</td>\n",
       "      <td>http://arabsinamerica.unc.edu/identity/veiling...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         snopes_page ...  tags\n",
       "0  http://www.snopes.com/georgia-bans-muslim-cult... ...   NaN\n",
       "1  http://www.snopes.com/georgia-bans-muslim-cult... ...   NaN\n",
       "\n",
       "[2 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out the data\n",
    "data = pd.read_csv('../input/snopes.csv')\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "fb7d9a007c9ce09cb783323778fc0220c68dc20a"
   },
   "outputs": [],
   "source": [
    "# Could keep in dataframe format? \n",
    "# Can make use of other fields for analysis/graph, since not a huge dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "d2a4e495e51b374006883cbae4984c77f585f79e"
   },
   "outputs": [],
   "source": [
    "# drop duplicate claims (and unneccesary columns?)\n",
    "data.drop_duplicates(subset='claim', inplace=True)\n",
    "\n",
    "# remove 'examples' (Some odd artifacts that messed with analysis)\n",
    "data = data.replace({'Example\\(s\\)': ''}, regex=True)\n",
    "data = data.replace({'\\s+': ' '}, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "52a9315244c933bc63699ee953d66b7f3e453454"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of claims:  3122\n"
     ]
    }
   ],
   "source": [
    "# remove duplicate claims (Not really needed since dropped already)\n",
    "claims = data.claim.unique()\n",
    "\n",
    "# make sure it's all strings \n",
    "# added lower and whitespace strip just in case\n",
    "# claims = [str(claim).lower().strip() for claim in claims]\n",
    "# Turns out this ruins it... and reduced most docs to few claims for some reason\n",
    "\n",
    "# NER list we'll use - Perhaps could be expanded?\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# intialize claim counter & lists for our entities\n",
    "coocur_edges = {}\n",
    "\n",
    "print('Number of claims: ', len(claims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "9bc6de66c72563977dacd8419c18245ecf14baed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Georgia recently became the first U.S. state to \"ban Muslim culture.\"\n",
      "[Georgia, first, U.S., Muslim]\n",
      "\n",
      "\n",
      "An Image depicts a fatal collision involving a Chevy Suburban that recklessly merged ahead of a tractor-trailer, resulting in the death of an infant. See \n",
      "[Chevy, Suburban]\n",
      "\n",
      "\n",
      "A special property of the equinox allows eggs (or brooms) to be balanced on their ends that day. See \n",
      "[that day]\n",
      "\n",
      "\n",
      "Sophia Stewart won a large judgment in a copyright infringement suit over authorship of the film The Matrix. See \n",
      "[Sophia Stewart, Matrix]\n",
      "\n",
      "\n",
      "Images show several large topiary cats created by a retiree and artist named John Brooker.\n",
      "[John Brooker]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lets look at the first few claims, along with the ents identified\n",
    "\n",
    "for doc in nlp.pipe(claims[:5]):\n",
    "    print(doc)\n",
    "    print(list(doc.ents))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "a609e748253f689dfa22809639e40627af390968"
   },
   "outputs": [],
   "source": [
    "# Separating this lengthy step, and saving result as a list rather than generator\n",
    "# (Size isnt too big, and saves a lot of time when reused later)\n",
    "\n",
    "# Spacy seems to have error at 3k doc mark? \n",
    "# Related to this maybe? https://github.com/explosion/spaCy/issues/1927\n",
    "# Continuing on with the first 3000 of 3122 for now\n",
    "\n",
    "corpus = list(nlp.pipe(claims[:3000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "d49a101a374d4a04a4fc7657cc8da9a4c95ef00a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct entities:  2730\n"
     ]
    }
   ],
   "source": [
    "# Looking at number of times each ent appears in the total corpus\n",
    "# nb. ents all appear as Spacy tokens, hence needing to cast as str\n",
    "\n",
    "all_ents = defaultdict(int)\n",
    "\n",
    "for i, doc in enumerate(corpus):\n",
    "    #print(i,doc)\n",
    "    for ent in doc.ents:\n",
    "        all_ents[str(ent)] += 1\n",
    "        \n",
    "print('Number of distinct entities: ', len(all_ents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "ca6cf21daf5ee334c7d5513cb976d527df85c03e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Donald Trump', 302),\n",
       " ('Hillary Clinton', 178),\n",
       " ('Obama', 145),\n",
       " ('U.S.', 94),\n",
       " ('2016', 74),\n",
       " ('Trump', 65),\n",
       " ('Muslim', 58),\n",
       " ('Bernie Sanders', 49),\n",
       " ('Facebook', 47),\n",
       " (\"Donald Trump's\", 46),\n",
       " ('the United States', 45),\n",
       " ('first', 37),\n",
       " ('two', 37),\n",
       " ('Republican', 37),\n",
       " ('Muslims', 36),\n",
       " ('American', 35),\n",
       " ('Americans', 33),\n",
       " ('Photograph', 31),\n",
       " ('America', 30),\n",
       " ('Russian', 29)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most popular ents\n",
    "\n",
    "sorted_ents = sorted(all_ents.items(), key=operator.itemgetter(1), reverse=True)\n",
    "sorted_ents[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "dbaa62ff9b1d0b1112f0a0020d94160d5a8af153"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ents that appear at least twice:  681\n"
     ]
    }
   ],
   "source": [
    "# Number of ents that appear at least twice\n",
    "\n",
    "multi_ents = [x for x in sorted_ents if x[1] > 1]\n",
    "\n",
    "print('Number of ents that appear at least twice: ', len(multi_ents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "eeefad7b4e419e015b0cbb41c90cca3e97b306ca"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# How many ents appear per claim?\n",
    "\n",
    "ents_in_claim = [len(doc.ents) for doc in corpus]\n",
    "\n",
    "plt.hist(ents_in_claim, \n",
    "         rwidth=0.9, \n",
    "         bins=np.arange(max(ents_in_claim)+2)-0.5)  \n",
    "        # Futzing with bins just to fix column alignment - not really necessary\n",
    "plt.title('Entities per claim')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "b50950168d7ec79feb3ea3736155f4f21afb82ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Georgia', 'first', 'U.S.', 'Muslim'],\n",
       " ['Georgia', 'first', 'U.S.', 'Muslim'],\n",
       " ['Chevy', 'Suburban'],\n",
       " ['that day'],\n",
       " ['that day'],\n",
       " ['Sophia Stewart', 'Matrix'],\n",
       " ['John Brooker'],\n",
       " ['John Brooker']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Listing claims as a list of their entities\n",
    "\n",
    "claim_ents = []\n",
    "for i, doc in enumerate(nlp.pipe(claims[:5])):\n",
    "    string_ents = list(map(str, doc.ents))\n",
    "    claim_ents.append(string_ents)\n",
    "    # Doubling some up to fake/force coocurrence\n",
    "    if i%2==0:\n",
    "        claim_ents.append(string_ents)  \n",
    "claim_ents\n",
    "\n",
    "# Could do as a one line list comprehension, though maybe not as readable:\n",
    "# claim_ents = [list(map(str, doc.ents)) for doc in nlp.pipe(claims[:10]*2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "94ab3010c24e72ac4561cc6782877f7071646e1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Georgia', 'first', 'U.S.', 'Muslim'],\n",
       " ['Georgia', 'first', 'U.S.', 'Muslim'],\n",
       " ['Chevy', 'Suburban'],\n",
       " ['Sophia Stewart', 'Matrix']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can filter out claims with only 1 ent (nothing to coocur with)\n",
    "\n",
    "multi_ent_claims = [c for c in claim_ents if len(c)>1]\n",
    "# single_ent_claims = [c for c in claim_ents if len(c)==1]\n",
    "# no_ent_claims = [c for c in claim_ents if len(c)==0]\n",
    "\n",
    "multi_ent_claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "dd2844a68696c0a83f92b25cecc1da293b7ccd0b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'Georgia': {'Muslim': {'weight': 2},\n",
       "              'U.S.': {'weight': 2},\n",
       "              'first': {'weight': 2}},\n",
       "             'Muslim': {'Georgia': {'weight': 2},\n",
       "              'U.S.': {'weight': 2},\n",
       "              'first': {'weight': 2}},\n",
       "             'U.S.': {'Georgia': {'weight': 2},\n",
       "              'Muslim': {'weight': 2},\n",
       "              'first': {'weight': 2}},\n",
       "             'first': {'Georgia': {'weight': 2},\n",
       "              'Muslim': {'weight': 2},\n",
       "              'U.S.': {'weight': 2}},\n",
       "             'Chevy': {'Suburban': {'weight': 1}},\n",
       "             'Suburban': {'Chevy': {'weight': 1}},\n",
       "             'Matrix': {'Sophia Stewart': {'weight': 1}},\n",
       "             'Sophia Stewart': {'Matrix': {'weight': 1}}})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating coocurrence dict of dicts\n",
    "\n",
    "coocur_edges = coocurrence(*multi_ent_claims)\n",
    "coocur_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "815e97b03d5d50d7a9063fc5ab81b994276ae4b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {'Georgia': {'Muslim': {'weight': 2},\n",
       "              'U.S.': {'weight': 2},\n",
       "              'first': {'weight': 2}},\n",
       "             'Muslim': {'Georgia': {'weight': 2},\n",
       "              'U.S.': {'weight': 2},\n",
       "              'first': {'weight': 2}},\n",
       "             'U.S.': {'Georgia': {'weight': 2},\n",
       "              'Muslim': {'weight': 2},\n",
       "              'first': {'weight': 2}},\n",
       "             'first': {'Georgia': {'weight': 2},\n",
       "              'Muslim': {'weight': 2},\n",
       "              'U.S.': {'weight': 2}},\n",
       "             'Chevy': {'Suburban': {'weight': 1}},\n",
       "             'Suburban': {'Chevy': {'weight': 1}},\n",
       "             'Matrix': {'Sophia Stewart': {'weight': 1}},\n",
       "             'Sophia Stewart': {'Matrix': {'weight': 1}}})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out ents with <2 weight - refactored into a function later.\n",
    "# (Could also use: del coocur_edges[k1][k2] rather than make new dict)\n",
    "\n",
    "coocur_edges_filtered = defaultdict()\n",
    "\n",
    "for k1, e in coocur_edges.items():\n",
    "    ents_over_2_weight = {k2: v for k2, v in e.items() if v['weight'] >= 1}\n",
    "    if ents_over_2_weight:  # ie. Not empty\n",
    "        coocur_edges_filtered[k1] = ents_over_2_weight\n",
    "\n",
    "coocur_edges_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "32043a3a14fbc3fdd2e89ab63c074b216ce0be57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Georgia', 6),\n",
       " ('Muslim', 6),\n",
       " ('U.S.', 6),\n",
       " ('first', 6),\n",
       " ('Chevy', 1),\n",
       " ('Suburban', 1),\n",
       " ('Matrix', 1),\n",
       " ('Sophia Stewart', 1)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summing all coocurrences in order to see most coocurring edges\n",
    "\n",
    "coocur_sum = defaultdict(int)\n",
    "for k1, e in coocur_edges_filtered.items():\n",
    "    for k2, v in e.items():\n",
    "        coocur_sum[k1] += v['weight']\n",
    "\n",
    "sorted_coocur = sorted(coocur_sum.items(), key=operator.itemgetter(1), reverse=True)\n",
    "sorted_coocur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "eb4271f29db804c952a5706c5e805328f3d4b4d1"
   },
   "outputs": [],
   "source": [
    "# Making the list of claims\n",
    "claim_ents = []\n",
    "for doc in corpus:\n",
    "    string_ents = list(map(str, doc.ents))\n",
    "    claim_ents.append(string_ents)\n",
    "    \n",
    "    \n",
    "# Keeping only claims with multiple entities\n",
    "multi_ent_claims = [c for c in claim_ents if len(c)>1]\n",
    "# single_ent_claims = [c for c in claim_ents if len(c)==1]\n",
    "# no_ent_claims = [c for c in claim_ents if len(c)==0]\n",
    "\n",
    "\n",
    "# Creating the coocurrance dict\n",
    "coocur_edges = coocurrence(*multi_ent_claims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "95d0b81d62720be094fc178b2e0dbf4416169ba4"
   },
   "outputs": [],
   "source": [
    "# Filter out ents with < min_weight - useful for graph clarity?\n",
    "\n",
    "def filter_ents_by_min_weight(edges, min_weight):\n",
    "    coocur_edges_filtered = defaultdict()\n",
    "    for k1, e in edges.items():\n",
    "        ents_over_x_weight = {k2: v for k2, v in e.items() if v['weight'] > min_weight}\n",
    "        if ents_over_x_weight:  # ie. Not empty\n",
    "            coocur_edges_filtered[k1] = ents_over_x_weight\n",
    "    return coocur_edges_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "841708c3ba643dd4b46b183d1d77b242fd4e0794"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent CO-ocurring entity:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Donald Trump', 169),\n",
       " ('Hillary Clinton', 107),\n",
       " ('Obama', 80),\n",
       " ('U.S.', 47),\n",
       " ('2016', 47),\n",
       " ('Republican', 24),\n",
       " ('first', 23),\n",
       " ('Trump', 22),\n",
       " ('American', 22),\n",
       " ('Bernie Sanders', 20),\n",
       " ('Muslims', 19),\n",
       " ('Russian', 16),\n",
       " ('Democratic', 16),\n",
       " ('Barack Obama', 15),\n",
       " ('Vladimir Putin', 15),\n",
       " ('Muslim', 14),\n",
       " ('Americans', 14),\n",
       " ('Washington', 12),\n",
       " ('Mike Pence', 11),\n",
       " ('Supreme Court', 11)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the most coocurring edges\n",
    "\n",
    "filtered_edges = filter_ents_by_min_weight(coocur_edges, 2)\n",
    "\n",
    "coocur_sum = defaultdict(int)\n",
    "for k1, e in filtered_edges.items():\n",
    "    for k2, v in e.items():\n",
    "        coocur_sum[k1] += v['weight']\n",
    "\n",
    "sorted_coocur = sorted(coocur_sum.items(), key=operator.itemgetter(1), reverse=True)\n",
    "print('Most frequent CO-ocurring entity:')\n",
    "sorted_coocur[:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
